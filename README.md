# Проект по предсказанию успешности товаров с маркетплейсов на основе их различных характеристик
---

Суть проекта в том, чтобы собрать все возможные характеристики товаров с маркетплейса (картинка, описание и т.д.), извлечь из них признаки и построить на их основе модель, которая будет предсказывать успешность товара (по придуманной метрике, тоже на основе характеристик)

В качестве категории товаров были выбраны **детские игрушки** как одно из наиболее популярных и интересных направлений на сегодняшний день. А для рассмотрения были выбраны позиции по этому разделу на WB. 

❓ Для чего вообще может быть полезен такой проект?

✅ Во-первых, сам по себе датасет уже может быть использован продавцом для анализа рынка, выявления разных закономерностей

✅ Во-вторых, при помощи построенной модели продавец может оценить потенциальную успешность товара перед запуском, сравнить его показатели и понять как они влияют на успешность

Как один из вариантов, проект можно представить в виде чат-бота, который будет принимать на вход характеристики товара и выдавать прогноз модели

---
# Шаг №1: [Парсинг данных](./wb_parser.ipynb)

Как уже говорилось, собирались карточки детских игрушек из каталога WB (https://www.wildberries.ru/catalog/podarki/detyam/igrushki). Были собраны следующие характеристики: цена, бренд, кол-во отзывов, описание товара и сама картинка. В итоге получилось собрать датасет из около 7000 наблюдений, который можно найти [здесь](./data/wb_data.csv) 

---
# Шаг №2: [Извлечение признаков](./preprocessing)

В нашем датасете оказались данные (картинки и тексты), которые нельзя обработать в обычном формате, из них нужно было извлечь признаки. 

В случае с картинками было решено самостоятельно разметить небольшой кусок данных (300-400 наблюдений) по принципу 1 - красивая картинка, привлекающая внимание, а 0 - не очень. Дальше нейронка доразметила и остальные объекты на основе этой информации. Тетрадку можно найти [тут](./preprocessing/wb_photos.ipynb) 

В случае текстов с описанием товара признаков было чуть больше: **кол-во символов**, **оценка эмоциональности текста** и **кластер** текста (при помощи кластеризации тексты были разбиты на 4 темы). 

В случае с кол-вом символов логика такая, что человеку может быть лень читать огромный текст, или наоборот он может хотеть подробного описания и это может влиять на покупку. Эмоциональный окрас также может привлекать человека купить товар. Для оценки эмоциональности текста был использован словарь Четверкина.

Итоговый датасет с признаками сохранен [тут](./data/final_df.csv)

---
# Шаг №3: [Оценивание модели](./models_wb.ipynb)

Для начала была выполнена вся грязная работа: очистка данных от пропусков, объединение редких категорий в группы (например, "дугое"), и т.д.

Дальше нужно было определиться с целевой переменной, которую мы будем предсказывать и которая должна характеризовать успешность товара. Хотелось использовать рейтинг товара, оставленный пользователями, но в то же время учитывать кол-во отзывов. Потому что, например, товар с рейтингом 4.5 при 10000 отзывов скорее всего будет лучше, чем товар с рейтингом 5 и всего 100 отзывами. В результате было решено использовать в качестве таргета логарифм числа отзывов, умноженный на рейтинг. 

Кроме задачи регрессии также решалась задача бинарной классификации, для этого таргет был разделен на две группы (успешный/нет) по следующему принципу:

<img width="733" height="505" alt="image" src="https://github.com/user-attachments/assets/8fba784d-509f-4cf9-b6c0-a35e7828a077" />

---
# Итоги

- Лучшие результаты ожидаемо показал бустинг. В случае с регрессией MAE получилосб около 3, при том, что среднее по целевой переменной у нас где-то 35. Качество оказалось сильно лучше наивного прогноза, то есть какой-то смысл в модели все-таки есть.

- В случае классификации после разбиения доля отрицательного класса оказалась 0.82, в то время как accuracy для бустинга составило 0.9. То есть опять получилась осмысленная модель. Очевидно, что здесь можно добиваться и более высокого качества, использовать нейронки, подбирать кучу параметров и т.д. но в целом уже есть неплохой результат.

- Также интересно, что самыми важными признаками в бустинге оказались длина текста, количество товара на складе, цена, эмоциональность описания, а также рейтинг производителя. То есть признаки, которые мы извлекали из текстов, оказались на самом деле полезными.

В результате получилась довольно неплохая модель, которая может использоваться при запуске нового продукта, когда продавец сомневается, какую ставить картинку товара, или каким сделать описание. Из возможных улучшений проекта: можно исследовать другие разделы (помимо детских игрушек), а также обернуть модель в чат-бот для удобного использования










